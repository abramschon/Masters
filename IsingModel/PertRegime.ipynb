{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39264bit3926084c7cc7f3d4f4391856d584bc48b87",
   "display_name": "Python 3.9.2 64-bit ('3.9.2')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Are we just in the perturbative regime?\n",
    "\n",
    "In the 2009 paper [Pairwise Maximum Entropy Models for Studying Large Biological Systems: When They Can Work and When They Can't](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000380), Roudi et al. suggest that when we are in the perturbative regime, characterised by a small mean probability of observing neurons spike and small number of neurons $N$, the pairwise maxent model can appear to be a good model for a distribution. However, we cannot extrapolate the behaviour of the pairwise model to larger $N$, and predict that it will remain a good fit outside of the perturbative regime. We try and investigate these claims computationally.\n",
    "\n",
    "The perturbative regime is defined as $N\\bar{v}\\delta t \\ll 1$, where $\\bar{v}$ is the mean firing rate, $\\delta t$ is the size of the time bin. For sufficiently small time bins where we observe at most one spike within each bin, and we can identify $\\bar{v}\\delta t $ with the mean probability of observing a neuron fire. Thus, for $N=5$ neurons, we should be in the perturbative regime with $\\bar{p}=\\bar{v}\\delta t \\ll 0.2$. With 5 states, it is possible to sum over all $2^5=32$ states, so we can work out quantities such as the KL divergence $D_{KL}(p\\| q) = \\sum_s p \\ln (p/q) $ exactly. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NumericIsing import Ising"
   ]
  },
  {
   "source": [
    "## All or nothing model\n",
    "We start by considering a very simple distribution that has higher order correlations. Let us say we have 5 neurons which always fire in sync. Thus $p(1,1,1,1,1) = c$, $p(0,0,0,0,0)=(1-c)$ and all other events have probability 0. The mean firing rate of individual neurons will be c, as will the correlations. We will vary the probability $c$ of all of them firing, and see whether the pairwise model appears to be a good fit. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5]\n[[0.  0.5 0.5 0.5 0.5]\n [0.  0.  0.5 0.5 0.5]\n [0.  0.  0.  0.5 0.5]\n [0.  0.  0.  0.  0.5]\n [0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "c = 0.5\n",
    "avgs = c*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "corrs = c*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(N, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted averages:\n[0.50380264 0.50383075 0.50452295 0.50528602 0.50601873]\nPredicted correlations:\n[[0.50380264 0.50217338 0.50154196 0.50113466 0.50072423]\n [0.         0.50383075 0.5007258  0.50031627 0.49993876]\n [0.         0.         0.50452295 0.49972255 0.49937287]\n [0.         0.         0.         0.50528602 0.49898707]\n [0.         0.         0.         0.         0.50601873]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "source": [
    "Now that we have trained a maximum entropy model, let us see what it thinks the true probability distribution looks like."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. 0. 0.] 0.48\n[1. 1. 1. 1. 1.] 0.5\n"
     ]
    }
   ],
   "source": [
    "for state in [p_wise.states[0],p_wise.states[-1]]:\n",
    "    print(state,np.round(p_wise.p(state),2))"
   ]
  },
  {
   "source": [
    "Interestingly, the pairwise model is able to accurately predict the full probability distribution of the 'all or nothing model' for different values of $c$. I honestly wasn't sure what to expect here, and would be interested in relating this to the results from the Roudi et al. paper. We will have to consider slightly more complex distributions to 'break' the pairwise model. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## A couple of states or nothing\n",
    "The next model that came to mind that takes on two states:\n",
    "\n",
    "- $p(0,1,1,1,1)=a$\n",
    "- $p(1,1,1,1,0)=b$\n",
    "- $p(0,0,0,0,0)=1-(a+b)$\n",
    "\n",
    "We define $a+b \\doteq c$\n",
    "\n",
    "The expectation of the neurons will be: \n",
    "\n",
    "    (b, c, c, c, c, a)\n",
    "\n",
    "The pairwise correlations will be:\n",
    "\n",
    "        1 2 3 4 5\n",
    "      1   b b b 0\n",
    "      2     c c a    \n",
    "      3       c a\n",
    "      4         a"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.4 0.6 0.6 0.6 0.2]\n[[0.  0.4 0.4 0.4 0. ]\n [0.  0.  0.6 0.6 0.2]\n [0.  0.  0.  0.6 0.2]\n [0.  0.  0.  0.  0.2]]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "a = 0.2\n",
    "b = 0.4\n",
    "c = a + b\n",
    "avgs = np.array([b, c, c, c, a])\n",
    "corrs = np.array([[0,b,b,b,0],\n",
    "                  [0,0,c,c,a],\n",
    "                  [0,0,0,c,a],\n",
    "                  [0,0,0,0,a]])\n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(N, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted averages:\n[0.40120964 0.60166855 0.60201396 0.60243361 0.20180175]\nPredicted correlations:\n[[0.40120964 0.40017571 0.40004125 0.39989105 0.00277631]\n [0.         0.60166855 0.60019171 0.59988656 0.19942072]\n [0.         0.         0.60201396 0.59956424 0.19928799]\n [0.         0.         0.         0.60243361 0.19916612]\n [0.         0.         0.         0.         0.20180175]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. 0. 0.] 0.392\n[0. 0. 0. 0. 1.] 0.002\n[0. 0. 0. 1. 0.] 0.002\n[0. 0. 0. 1. 1.] 0.0\n[0. 0. 1. 0. 0.] 0.001\n[0. 0. 1. 0. 1.] 0.0\n[0. 0. 1. 1. 0.] 0.0\n[0. 0. 1. 1. 1.] 0.0\n[0. 1. 0. 0. 0.] 0.0\n[0. 1. 0. 0. 1.] 0.0\n[0. 1. 0. 1. 0.] 0.0\n[0. 1. 0. 1. 1.] 0.0\n[0. 1. 1. 0. 0.] 0.0\n[0. 1. 1. 0. 1.] 0.001\n[0. 1. 1. 1. 0.] 0.004\n[0. 1. 1. 1. 1.] 0.196\n[1. 0. 0. 0. 0.] 0.001\n[1. 0. 0. 0. 1.] 0.0\n[1. 0. 0. 1. 0.] 0.0\n[1. 0. 0. 1. 1.] 0.0\n[1. 0. 1. 0. 0.] 0.0\n[1. 0. 1. 0. 1.] 0.0\n[1. 0. 1. 1. 0.] 0.0\n[1. 0. 1. 1. 1.] 0.0\n[1. 1. 0. 0. 0.] 0.0\n[1. 1. 0. 0. 1.] 0.0\n[1. 1. 0. 1. 0.] 0.0\n[1. 1. 0. 1. 1.] 0.0\n[1. 1. 1. 0. 0.] 0.001\n[1. 1. 1. 0. 1.] 0.0\n[1. 1. 1. 1. 0.] 0.396\n[1. 1. 1. 1. 1.] 0.003\n"
     ]
    }
   ],
   "source": [
    "for state in p_wise.states:\n",
    "    print(state,np.round(p_wise.p(state),3))"
   ]
  },
  {
   "source": [
    "Again, the pairwise model is able to capture the probability distribution.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## XOR \n",
    "\n",
    "In the 2003 Schneidman paper, *Network Information and Connected Correlations*, they say,\n",
    "\n",
    "> if $\\sigma_3$ is formed as the exclusive OR (XOR) of the variables $\\sigma_1$ and $\\sigma_2$, then the essential structure of $p(\\sigma_1,\\sigma_2,\\sigma_3)$ is contained in a threeâ€“spin interaction. \n",
    "\n",
    "This might give us a simple example of something the ising model can't model.\n",
    "\n",
    "Let us say that $\\sigma_1$ and $\\sigma_2$ firing independently with probabilities $p(\\sigma_1{=}1)=a$ and $p(\\sigma_2{=}1)=b$. \n",
    "\n",
    "        s_1 s_2 s_3  p(s_1, s_2, s_3)\n",
    "        0   0   0    (1-a)(1-b)\n",
    "        0   1   1    (1-a)b\n",
    "        1   0   1    a(1-b)\n",
    "        1   1   0    ab\n",
    "Thus, the averages are:\n",
    "\n",
    "        (a, b, b+a-2ab)\n",
    "\n",
    "And the correlations are:\n",
    "\n",
    "        s_1 s_2, s_1 s_3, s_2,s_3\n",
    "        ab       a(1-b)   (1-a)b        "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2  0.4  0.44]\n[[0.   0.08 0.12]\n [0.   0.   0.32]]\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "a = 0.2\n",
    "b = 0.4\n",
    "avgs = np.array([a,b,b+a-2*a*b])\n",
    "corrs = np.array([[0,a*b,a*(1-b)],\n",
    "                  [0,0,(1-a)*b]])\n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(3, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted averages:\n[0.20000128 0.40000042 0.44000421]\nPredicted correlations:\n[[0.20000128 0.08000851 0.11999224]\n [0.         0.40000042 0.31999632]\n [0.         0.         0.44000421]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0.] 0.406\n[0. 0. 1.] 0.074\n[0. 1. 0.] 0.074\n[0. 1. 1.] 0.246\n[1. 0. 0.] 0.074\n[1. 0. 1.] 0.046\n[1. 1. 0.] 0.006\n[1. 1. 1.] 0.074\n"
     ]
    }
   ],
   "source": [
    "for state in p_wise.states:\n",
    "    print(state,np.round(p_wise.p(state),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0] 0.48\n[0, 1, 1] 0.32000000000000006\n[1, 0, 1] 0.12\n[1, 1, 0] 0.08000000000000002\n"
     ]
    }
   ],
   "source": [
    "print([0,0,0], (1-a)*(1-b))\n",
    "print([0,1,1], (1-a)*b)\n",
    "print([1,0,1], a*(1-b))\n",
    "print([1,1,0], a*b)"
   ]
  },
  {
   "source": [
    "Notice how the events `[0,0,1]` and `[1,1,1]` are assigned non-zero probabilities, when they should in fact be zero. In general, we can see the predictions are far off. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}