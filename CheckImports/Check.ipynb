{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick notebook to check all the code imports\n",
    "\n",
    "Though going forward, I will start writing tests, in the meanwhile here is some quick tests to see all is okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Ising with Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxEnt import NumIsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pert_init(avgs = 0.05*np.ones(5), corrs = 0.002*np.triu(np.ones((5,5)),1)):  \n",
    "    N = 5\n",
    "    avgs = avgs # prob of every neuron firing in a window is 0.5\n",
    "    corrs = corrs # prob of 2 neurons firing in the same window is 0.2 \n",
    "    print(\"Init model\")\n",
    "    ising = NumIsing(N, avgs, corrs, lr=0.5,analytic=True) \n",
    "    ising.pert_init()\n",
    "    print(ising.avgs, ising.corrs)\n",
    "    \n",
    "    pred_avgs = ising.averages(analytic=True)\n",
    "    print(\"Predicted averages:\", np.round(pred_avgs,4))\n",
    "    pred_corrs = ising.correlations(analytic=True)\n",
    "    print(\"Predicted correlations:\", np.round(pred_corrs,4))\n",
    "\n",
    "def test_MC():\n",
    "    N=20\n",
    "    \n",
    "    avgs = 0.05*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "    corrs = 0.002*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "    print(\"Init model\")\n",
    "    ising = NumIsing(N, avgs, corrs, lr=0.5)\n",
    "    ising.pert_init()\n",
    "    ising.save_samples()\n",
    "    print(\"Init averages\",ising.averages(compute=True))\n",
    "    \n",
    "    print(\"State space \", 2**N)\n",
    "    N_samples=1000; chains=4; N_sets=10; updates_per_set=100; M = N_samples*chains\n",
    "    print(f\"{N_sets} sets of {M} samples will be generated, for a total of {N_sets*M} states\")\n",
    "    \n",
    "    print(\"Starting gradient ascent with sampling\")\n",
    "    start = time.time()\n",
    "    ising.num_gradient_ascent(N_samples, chains, N_sets, updates_per_set) \n",
    "    stop = time.time()\n",
    "    print(\"Stop grad ascent, time: \",stop-start,\"s\")\n",
    "    \n",
    "    pred_avgs = ising.averages()\n",
    "    print(\"Predicted averages:\", np.round(pred_avgs,4))\n",
    "    # pred_corrs = ising.correlations()\n",
    "    # print(\"Predicted correlations:\", np.round(pred_corrs,4))\n",
    "\n",
    "\n",
    "def test_correlations():\n",
    "    N = 5\n",
    "    avgs = 0.5*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "    corrs = 0.2*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "    \n",
    "    print(\"Init model\")\n",
    "    ising = NumIsing(N, avgs, corrs, lr=0.5,analytic=True) \n",
    "    \n",
    "    print(\"Starting grad ascent\")\n",
    "    ising.num_gradient_ascent() #\n",
    "    print(\"Stop grad ascent\")\n",
    "    \n",
    "    pred_avgs = ising.mod_avgs\n",
    "    pred_corrs = ising.mod_corrs\n",
    "    print(\"Predicted averages:\", np.round(pred_avgs,4), \"Predicted correlations:\", np.round(pred_corrs,4),sep=\"\\n\")\n",
    "\n",
    "    #test averages\n",
    "    print(\"Default\", ising.correlations())\n",
    "    print(\"Analytic\", ising.correlations(analytic=True))\n",
    "    print(\"Compute\",ising.correlations(compute=True))\n",
    "    ising.save_samples()\n",
    "    print(\"After more samples\",ising.correlations(compute=True))\n",
    "\n",
    "def test_samples(): #fix this\n",
    "    N = 10\n",
    "    print(\"Init model\")\n",
    "    ising = NumIsing(N, 0.5*np.ones(N), 0.2*np.triu(np.ones((N,N)),1), lr=0.5, analytic=True) \n",
    "\n",
    "    M = 500000\n",
    "    chains = 10\n",
    "    start = time.time()\n",
    "    samples = ising.gibbs_sampling(M,chains)\n",
    "    stop = time.time()\n",
    "    print(f\"Time to generate {chains}x{M} samples\", stop-start)\n",
    "\n",
    "    means_true = ising.averages(analytic=True)\n",
    "    means_sample = np.mean(samples, axis=0)\n",
    "    \n",
    "    dp = 5 #decimal places\n",
    "    print(\"True means\", np.round(means_true,dp), \"Sample means\", np.round(means_sample,dp), sep=\"\\n\")\n",
    "    print(\"Difference in means\", means_true - means_sample, sep=\"\\n\")\n",
    "\n",
    "    corrs_true = ising.correlations(analytic=True)\n",
    "    corrs_sample = np.triu((samples.T@samples) / samples.shape[0],k=1)\n",
    "    print(\"True correlations\", np.round(corrs_true,dp), \"Sample correlations\", np.round(corrs_sample,dp), sep=\"\\n\")\n",
    "    print(\"Difference in correlations\", corrs_true - corrs_sample, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "[0.03 0.03 0.03 0.03 0.03] [[0.    0.002 0.002 0.002 0.002]\n",
      " [0.    0.    0.002 0.002 0.002]\n",
      " [0.    0.    0.    0.002 0.002]\n",
      " [0.    0.    0.    0.    0.002]\n",
      " [0.    0.    0.    0.    0.   ]]\n",
      "Predicted averages: [0.0355 0.0355 0.0355 0.0355 0.0355]\n",
      "Predicted correlations: [[0.    0.003 0.003 0.003 0.003]\n",
      " [0.    0.    0.003 0.003 0.003]\n",
      " [0.    0.    0.    0.003 0.003]\n",
      " [0.    0.    0.    0.    0.003]\n",
      " [0.    0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "test_pert_init(avgs = 0.03*np.ones(5), corrs = 0.002*np.triu(np.ones((5,5)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "Init averages [0.043    0.0445   0.04255  0.0435   0.035    0.050125 0.04515  0.048\n",
      " 0.032    0.0425   0.0475   0.0345   0.0415   0.034    0.0435   0.053125\n",
      " 0.04     0.0415   0.04795  0.040525]\n",
      "State space  1048576\n",
      "10 sets of 4000 samples will be generated, for a total of 40000 states\n",
      "Starting gradient ascent with sampling\n",
      "Stop grad ascent, time:  5.688671112060547 s\n",
      "Predicted averages: [0.0329 0.0422 0.0601 0.058  0.0539 0.0504 0.0523 0.0367 0.049  0.0588\n",
      " 0.0548 0.0563 0.0533 0.0689 0.0238 0.0522 0.0505 0.0371 0.0359 0.0357]\n"
     ]
    }
   ],
   "source": [
    "test_MC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "Starting grad ascent\n",
      "Stop grad ascent\n",
      "Predicted averages:\n",
      "[0.4826 0.4894 0.4878 0.487  0.492 ]\n",
      "Predicted correlations:\n",
      "[[0.     0.2097 0.2074 0.2093 0.2069]\n",
      " [0.     0.     0.2074 0.204  0.1988]\n",
      " [0.     0.     0.     0.2052 0.2038]\n",
      " [0.     0.     0.     0.     0.2064]\n",
      " [0.     0.     0.     0.     0.    ]]\n",
      "Default [[0.         0.20972124 0.2073784  0.20931581 0.20692516]\n",
      " [0.         0.         0.20742646 0.2039736  0.1988193 ]\n",
      " [0.         0.         0.         0.20515899 0.20378105]\n",
      " [0.         0.         0.         0.         0.20639513]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "Analytic [[0.         0.2148272  0.2080379  0.22528282 0.2091629 ]\n",
      " [0.         0.         0.19045851 0.21458755 0.20765018]\n",
      " [0.         0.         0.         0.19483903 0.19021568]\n",
      " [0.         0.         0.         0.         0.18863419]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "Compute [[0.      0.19375 0.21125 0.2075  0.215  ]\n",
      " [0.      0.      0.198   0.18225 0.18275]\n",
      " [0.      0.      0.      0.2065  0.2175 ]\n",
      " [0.      0.      0.      0.      0.2155 ]\n",
      " [0.      0.      0.      0.      0.     ]]\n",
      "After more samples [[0.         0.21179545 0.20670455 0.22356818 0.20777273]\n",
      " [0.         0.         0.18868182 0.21290909 0.199     ]\n",
      " [0.         0.         0.         0.19538636 0.18584091]\n",
      " [0.         0.         0.         0.         0.18656818]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "Time to generate 10x500000 samples 3.9725329875946045\n",
      "True means\n",
      "[0.25369 0.17027 0.23762 0.20605 0.23671 0.30887 0.19493 0.26086 0.1286\n",
      " 0.19003]\n",
      "Sample means\n",
      "[0.25355 0.1706  0.23853 0.20576 0.23647 0.30838 0.19477 0.26083 0.1284\n",
      " 0.18993]\n",
      "Difference in means\n",
      "[ 1.31531687e-04 -3.27371009e-04 -9.15292932e-04  2.94867351e-04\n",
      "  2.42117921e-04  4.94981806e-04  1.62135535e-04  2.87544652e-05\n",
      "  2.04652259e-04  9.46266481e-05]\n",
      "True correlations\n",
      "[[0.      0.04147 0.04922 0.03394 0.06056 0.05539 0.04732 0.05343 0.0294\n",
      "  0.03237]\n",
      " [0.      0.      0.02831 0.03373 0.03818 0.0534  0.02102 0.03671 0.02124\n",
      "  0.02487]\n",
      " [0.      0.      0.      0.03862 0.04852 0.07822 0.03425 0.04646 0.03178\n",
      "  0.0291 ]\n",
      " [0.      0.      0.      0.      0.03561 0.05618 0.0291  0.04784 0.02488\n",
      "  0.03238]\n",
      " [0.      0.      0.      0.      0.      0.05863 0.03675 0.04773 0.01833\n",
      "  0.04829]\n",
      " [0.      0.      0.      0.      0.      0.      0.05054 0.08336 0.02419\n",
      "  0.04666]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.05117 0.02256\n",
      "  0.02476]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.      0.02609\n",
      "  0.05125]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.01303]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.     ]]\n",
      "Sample correlations\n",
      "[[0.      0.04163 0.04906 0.03391 0.06075 0.05501 0.04725 0.05333 0.02946\n",
      "  0.03251]\n",
      " [0.      0.      0.02849 0.03386 0.0383  0.0537  0.02104 0.03674 0.02114\n",
      "  0.02512]\n",
      " [0.      0.      0.      0.03873 0.04854 0.07845 0.03454 0.04668 0.03181\n",
      "  0.029  ]\n",
      " [0.      0.      0.      0.      0.03571 0.05596 0.02925 0.048   0.02486\n",
      "  0.03233]\n",
      " [0.      0.      0.      0.      0.      0.05822 0.0366  0.04752 0.01833\n",
      "  0.04813]\n",
      " [0.      0.      0.      0.      0.      0.      0.05059 0.08359 0.02402\n",
      "  0.04641]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.05089 0.02251\n",
      "  0.02455]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.      0.02577\n",
      "  0.05112]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.01312]\n",
      " [0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "  0.     ]]\n",
      "Difference in correlations\n",
      "[[ 0.00000000e+00 -1.66357612e-04  1.57468497e-04  3.57568661e-05\n",
      "  -1.89811040e-04  3.84535803e-04  6.97792419e-05  1.02323924e-04\n",
      "  -5.87214295e-05 -1.43016176e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.81064517e-04 -1.27209078e-04\n",
      "  -1.12370479e-04 -3.00383695e-04 -2.07006681e-05 -2.80791943e-05\n",
      "   1.06423292e-04 -2.50118482e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.06837459e-04\n",
      "  -2.01040373e-05 -2.30768848e-04 -2.81770239e-04 -2.25791038e-04\n",
      "  -2.87483037e-05  1.04567709e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.02502171e-04  2.20819374e-04 -1.43330686e-04 -1.58327914e-04\n",
      "   1.99690989e-05  5.38243547e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.09643154e-04  1.48883308e-04  2.12280945e-04\n",
      "   3.90931733e-06  1.59588361e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -4.78033715e-05 -2.25947139e-04\n",
      "   1.68935540e-04  2.49155037e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.86259525e-04\n",
      "   4.97180422e-05  2.12049185e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   3.25866571e-04  1.26591742e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -8.62474731e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Ising without sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxEnt import Ising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_example():\n",
    "    N = 5\n",
    "    avgs = 0.5*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "    corrs = 0.2*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "    \n",
    "    print(\"Init model\")\n",
    "    ising = Ising(N, avgs, corrs, lr=0.5) \n",
    "    \n",
    "    print(\"Starting grad ascent\")\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        ising.gradient_ascent() # 500 steps \n",
    "    print(f\"Stop grad ascent: {time.time()-start}s\")\n",
    "    \n",
    "    pred_avgs = ising.averages()\n",
    "    pred_corrs = ising.correlations()\n",
    "    print(\"Predicted averages:\", pred_avgs, \"Predicted correlations:\", pred_corrs,sep=\"\\n\")\n",
    "    print(f\"P({ising.states[0]})={ising.p(ising.states[0])}\")\n",
    "\n",
    "def av_time_grad_ascent():\n",
    "    # Calculate average times\n",
    "    reps = 50\n",
    "    startN = 8\n",
    "    stopN = 10 #inclusive\n",
    "    Ns = np.arange(startN,stopN+1)\n",
    "    times = np.zeros( (reps,len(Ns)) )\n",
    "    for i in range(reps):\n",
    "        if not (i+1)%10:\n",
    "            print(\"Repetitions: \", i+1)\n",
    "        for N in Ns:\n",
    "            avgs = 0.5*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "            corrs = 0.2*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "            ising = Ising(N, avgs, corrs, lr=0.5) \n",
    "            start = time.time()\n",
    "            ising.gradient_ascent() # 500 steps \n",
    "            stop = time.time()\n",
    "            times[i,N-startN]=stop-start\n",
    "    \n",
    "    av_times = np.mean(times,0)\n",
    "    std_times = np.std(times,0)\n",
    "\n",
    "    plt.plot(Ns, av_times, \"k.\")\n",
    "    plt.plot(Ns, av_times+2*std_times/np.sqrt(reps), \"r_\")\n",
    "    plt.plot(Ns, av_times-2*std_times/np.sqrt(reps), \"r_\")\n",
    "    plt.title(\"Time for 100 steps of grad. ascent vs. system size\")\n",
    "    plt.xlabel(\"System size\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "Starting grad ascent\n",
      "Stop grad ascent: 1.081038236618042s\n",
      "Predicted averages:\n",
      "[0.49919728 0.49919728 0.49919728 0.49919728 0.49919728]\n",
      "Predicted correlations:\n",
      "[[0.         0.20039872 0.20039872 0.20039872 0.20039872]\n",
      " [0.         0.         0.20039872 0.20039872 0.20039872]\n",
      " [0.         0.         0.         0.20039872 0.20039872]\n",
      " [0.         0.         0.         0.         0.20039872]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "P([0 0 0 0 0])=7.359000155837554e-07\n"
     ]
    }
   ],
   "source": [
    "fit_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitions:  10\n",
      "Repetitions:  20\n",
      "Repetitions:  30\n",
      "Repetitions:  40\n",
      "Repetitions:  50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d32d021fa7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mav_time_grad_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-b9eff176bcf8>\u001b[0m in \u001b[0;36mav_time_grad_ascent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mising\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mising\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 500 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstartN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Masters/Code/src/MaxEnt/NumericIsing.py\u001b[0m in \u001b[0;36mgradient_ascent\u001b[0;34m(self, max_it)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Masters/Code/src/MaxEnt/NumericIsing.py\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# work out corrections to J\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mmod_corrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mJ_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmod_corrs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "av_time_grad_ascent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test K-Pairwise without sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxEnt import KPair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 7\n",
    "avgs = 0.5*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "corrs = np.triu(np.ones((N,N)),1)/3 # prob of 2 neurons firing in the same window is 0.333\n",
    "p_k = np.ones(N+1)/(N+1) # prob of k neurons firing is uniform\n",
    "\n",
    "print(\"Init model\")\n",
    "kpair = KPair(N, avgs, corrs, p_k, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grad ascent\n",
      "Stop grad ascent: 1.0277791023254395s\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting grad ascent\")\n",
    "start = time.time()\n",
    "for _ in range(4):\n",
    "    kpair.gradient_ascent() # 500 steps \n",
    "print(f\"Stop grad ascent: {time.time()-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "averages:\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "correlations:\n",
      "[[0.         0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333]\n",
      " [0.         0.         0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333]\n",
      " [0.         0.         0.         0.33333333 0.33333333 0.33333333\n",
      "  0.33333333]\n",
      " [0.         0.         0.         0.         0.33333333 0.33333333\n",
      "  0.33333333]\n",
      " [0.         0.         0.         0.         0.         0.33333333\n",
      "  0.33333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.33333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "p(K)\n",
      "[0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "P([0 0 0 0 0 0 0])=0.12499999999999999\n"
     ]
    }
   ],
   "source": [
    "pred_avgs = kpair.averages()\n",
    "pred_corrs = kpair.correlations()\n",
    "pred_p_k = kpair.prob_k()\n",
    "print(\"Predicted:\\naverages:\", pred_avgs, \"correlations:\", pred_corrs, \"p(K)\", pred_p_k,sep=\"\\n\")\n",
    "print(f\"P({kpair.states[0]})={kpair.p(kpair.states[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test threewise dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxEnt import ThreeWise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between 0,1,2\n",
      " 0.0016569727567211031\n",
      "Correlation between 0,1,3\n",
      " 0.010221243702375963\n",
      "Correlation between 0,2,3\n",
      " 0.006279566482332794\n",
      "Correlation between 1,2,3\n",
      " 0.0032954507812045473\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "h = np.random.random_sample((N))\n",
    "J = np.triu( np.random.random_sample((N,N)), 1)\n",
    "K = np.zeros((N,N,N))\n",
    "\n",
    "alpha = 1\n",
    "for i in range(N-2):\n",
    "    for j in range(i+1,N-1):\n",
    "        for k in range(j+1, N):\n",
    "            K[i,j,k] = alpha \n",
    "            alpha /= 10\n",
    "ex = ThreeWise(N, h, J, K)\n",
    "\n",
    "#calc 3 wise correlations\n",
    "for i in range(N-2):\n",
    "    for j in range(i+1,N-1):\n",
    "        for k in range(j+1, N):\n",
    "            print(f\"Correlation between {i},{j},{k}\\n\", ex.expectation(lambda s: s[:,i]*s[:,j]*s[:,k]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test coarse models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxEnt import Independent, PopCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "Time: 0.024595975875854492s\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "avgs = 0.5*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "print(\"Init model\")\n",
    "start = time.time()\n",
    "ind = Independent(N, avgs) \n",
    "print(f\"Time: {time.time()-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "P([0 0 0 0 0 0 0 0 0 0])=0.0009765625\n"
     ]
    }
   ],
   "source": [
    "pred_avgs = ind.averages()\n",
    "print(\"Predicted averages:\", pred_avgs, sep=\"\\n\")\n",
    "print(f\"P({ind.states[0]})={ind.p(ind.states[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ind.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.503675 , 0.4933225, 0.501925 , 0.49805  , 0.50539  , 0.494725 ,\n",
       "       0.50206  , 0.5007925, 0.499155 , 0.5023725])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(samples,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model\n",
      "Time: 0.02677297592163086s\n"
     ]
    }
   ],
   "source": [
    "# Pop Count\n",
    "N = 10\n",
    "p_K = np.ones(N+1)/(N+1) \n",
    "print(\"Init model\")\n",
    "start = time.time()\n",
    "pop = PopCount(N,p_K)\n",
    "print(f\"Time: {time.time()-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(K):\n",
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "P([0 0 0 0 0 0 0 0 0 0])=0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "pred_p_k = pop.prob_k()\n",
    "print(\"P(K):\", pred_p_k, sep=\"\\n\")\n",
    "print(f\"P({pop.states[0]})={pop.p(pop.states[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333326"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.expectation(lambda s: s[:,0]*s[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pop.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[0.0931075 0.0928925 0.0919475 0.09159   0.0900375 0.0896675 0.0884875\n",
      " 0.0890925 0.088515  0.089755  0.0949075]\n"
     ]
    }
   ],
   "source": [
    "sample_p_K = np.bincount(np.sum(samples,axis=1).astype(int))/len(samples)\n",
    "print(p_K,sample_p_K,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    \n",
    "    @staticmethod\n",
    "    def call_other():\n",
    "        test.call_this()\n",
    "        \n",
    "    @staticmethod\n",
    "    def call_this():\n",
    "        print(\"hello_world\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello_world\n"
     ]
    }
   ],
   "source": [
    "test.call_other()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
