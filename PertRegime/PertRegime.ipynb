{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are we just in the perturbative regime?\n",
    "\n",
    "In the 2009 paper [Pairwise Maximum Entropy Models for Studying Large Biological Systems: When They Can Work and When They Can't](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000380), Roudi et al. suggest that when we are in the perturbative regime, characterised by a small mean probability of observing neurons spike and small number of neurons $N$, the pairwise maxent model can appear to be a good model for a distribution. However, we cannot extrapolate the behaviour of the pairwise model to larger $N$, and predict that it will remain a good fit outside of the perturbative regime. In short:\n",
    "\n",
    "> The distance between the pairwise model and **any** probability distribution appears linear in $N\\bar{v}\\delta t$ in the perturbative regime \n",
    "\n",
    "We try and investigate these claims computationally.\n",
    "\n",
    "The perturbative regime is defined as $N\\bar{v}\\delta t \\ll 1$, where $\\bar{v}$ is the mean firing rate and $\\delta t$ is the size of the time bin. As shorthand, we define $\\delta \\doteq \\bar{v}\\delta t$.  For sufficiently small time bins where we observe at most one spike within each bin, and we can identify $\\delta$ with the mean probability of observing a neuron fire. \n",
    "\n",
    "As an example, for $N=5$ neurons, we should be in the perturbative regime with $\\bar{p}(r_i=1)=\\delta \\ll 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from NumericIsing import Ising\n",
    "from ThreeWise import ThreeWise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try and reproduce the main computational results in the paper. These results show close agreement between the true distance measure between the 'pairwise' and a '3-wise distribution', and an estimate of the distance measure between these distributions, whilst in the perturbative regime. \n",
    "\n",
    "First, we create a '3-wise distribution'. More accurately, we define the interactions in a model that includes up to 3-wise interactions, which creates a distribution that cannot be explained by a model that includes only up to pairwise interactions. \n",
    "\n",
    "This distribution takes the form:\n",
    "$$\n",
    "    P^{(3)}(\\{r_i\\}) = \\frac{1}{Z} \\exp \\left[ \\sum_i h_i r + \\sum_{i< j} J_{ij}r_i r_j  + \\sum_{i<j<k} K_{ijk}r_i r_j r_k  \\right]\n",
    "$$\n",
    "From the paper, the interaction terms were determined as:\n",
    "- $h_i = - \\ln (1/r_i^* - 1)$, where each $r_i^*$ is randomly drawn from an exponential distribution with mean 0.02\n",
    "- $J_{ij}$ is drawn from a Gaussian distribution with mean 0.05 and s.d. 0.8\n",
    "- $K_{ijk}$ is drawn from a Gaussian distribution with mean 0.02 and s.d. 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_p_true(N):\n",
    "    \"\"\"\n",
    "    Function that creates a distribution that includes up to 3-wise interactions,\n",
    "    by randomly sampling the interaction weights from the distributions specified in the paper\n",
    "    \"\"\"\n",
    "    h = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        h[i] = -np.log(1/np.random.exponential(0.02) - 1)\n",
    "        \n",
    "    J = np.zeros((N,N))\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1,N):\n",
    "            J[i,j] = np.random.normal(0.05, 0.8)\n",
    "            \n",
    "    K = np.zeros((N,N,N))\n",
    "    for i in range(N-2):\n",
    "        for j in range(i+1,N-1):\n",
    "            for k in range(j+1,N):\n",
    "                K[i,j,k] = np.random.normal(0.02, 0.5)\n",
    "    \n",
    "    p_true = ThreeWise(N, h, J, K)\n",
    "    return p_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between 0,1,2\n",
      " 4.873607574131338e-05\n",
      "Correlation between 0,1,3\n",
      " 6.587922158168148e-06\n",
      "Correlation between 0,2,3\n",
      " 1.205340759886893e-05\n",
      "Correlation between 1,2,3\n",
      " 3.8210339069379875e-05\n"
     ]
    }
   ],
   "source": [
    "p_true = sim_p_true(4)\n",
    "#calc 3 wise correlations\n",
    "for i in range(p_true.N-2):\n",
    "    for j in range(i+1,p_true.N-1):\n",
    "        for k in range(j+1, p_true.N):\n",
    "            print(f\"Correlation between {i},{j},{k}\\n\",p_true.expectation(lambda s: s[0]*s[1]*s[2], [i,j,k], p_true.p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main results in the paper are, in the perturbative regime:\n",
    "- $\\Delta_N = D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {pair }}\\right) / D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {ind }}\\right)$ scales as $(N-2)\\delta + \\mathcal{O}\\left((N \\delta)^{2}\\right)$ (I assume the power of 2 is just a safe upper bound). \n",
    "- $$D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {pair }}\\right)=\\frac{1}{\\ln 2} \\sum_{i<j<k} \\bar{r}_{i} \\bar{r}_{j} \\bar{r}_{k} f\\left(\\bar{\\boldsymbol{\\rho}}_{ijk}^{\\text{true}}, \\bar{\\boldsymbol{\\rho}}_{i j k}^{\\text{pair}}\\right)+\\mathcal{O}\\left((N \\delta)^{4}\\right)$$\n",
    "- $$D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {ind }}\\right)=\\frac{1}{\\ln 2} \\sum_{i<j} \\bar{r}_{i} \\bar{r}_{j} f\\left(\\rho_{i j}^{\\text{true}}, 0\\right)+\\mathcal{O}\\left((N \\delta)^{3}\\right)$$\n",
    "\n",
    "The KL divergence is defined as $D_{KL}(p\\| q) \\doteq \\sum_s p_s \\log_2 (p_s/q_s) $, where we sum over all states $s$. $f(x,y) \\doteq (1+x)\\big[\\ln(1+x)-\\ln(1+y)\\big] - (x-y)$, $\\overline{r}_i = \\langle r \\rangle $ (they use $r$ instead of $\\sigma$ in the paper), $\\rho_{ij}$ is the normalised pairwise correlation defined as:\n",
    "$$\n",
    "    \\rho_{ij} \\doteq \\frac{\\langle r_i r_j \\rangle - \\bar{r_i} \\bar{r_j}}{\\bar{r_i} \\bar{r_j}}\n",
    "$$\n",
    "and $\\bar{\\boldsymbol{\\rho}}_{i j k}^{p}$ is defined as:\n",
    "$$\n",
    "    \\bar{\\boldsymbol{\\rho}}_{i j k}^{p} \\doteq \\frac{\\langle r_i r_j r_k \\rangle - \\bar{r_i} \\bar{r_j} \\bar{r_k}}{\\bar{r_i} \\bar{r_j} \\bar{r_k}}\n",
    "$$\n",
    "Note, $\\bar{\\boldsymbol{\\rho}}_{i j k}^{p}$ depends on the distribution $p$ that is used to calculate the expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(p):\n",
    "    avgs = p.averages() #get the averages \\bar{r}\n",
    "    corrs_2 = p.correlations() #get the pairwise correlations <r_i r_j>\n",
    "    \n",
    "    N = p.N #how many neurons\n",
    "    \n",
    "    #calc all the \\rho_{ij}\n",
    "    rho = np.zeros((N,N))\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1,N):\n",
    "            rho[i,j]= corrs_2[i,j]/(avgs[i]*avgs[j]) - 1\n",
    "            \n",
    "    #calc all the \\bar{\\rho}_{ijk}\n",
    "    rho_b = np.zeros((N,N,N))\n",
    "    corrs_3 = np.zeros((N,N,N))\n",
    "    for i in range(N-2):\n",
    "        for j in range(i+1,N-1):\n",
    "            for k in range(j+1,N):\n",
    "                corrs_3[i,j,k]= p.expectation(lambda s: s[0]*s[1]*s[2], [i,j,k], p.p) \n",
    "                rho_b[i,j,k] = corrs_3[i,j,k] / (avgs[i]*avgs[j]*avgs[k]) - 1\n",
    "                \n",
    "    return avgs, corrs_2, corrs_3, rho, rho_b\n",
    "\n",
    "def f(x,y):\n",
    "    return (1+x)*(np.log(1+x) - np.log(1+y)) - (x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test all of this out, let's define a model that models the probability of each neuron firing as being independent. This corresponds to setting the 'local fields' $h_i$ to $\\ln(\\bar{r}_i/(1-\\bar{r}_i))$, and all other interaction parameters to 0. The expectations $\\langle r_i r_j ... r_p \\rangle$ should purely be products of the expectations of seeing indivdual neurons fire $\\bar{r}_i \\bar{r}_j ... \\bar{r}_p$. Hence, the normalised correlations should all be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "r_bar = np.ones(N)*0.4\n",
    "h = -np.log(1/r_bar - 1)\n",
    "J = np.zeros((N,N))\n",
    "K = np.zeros((N,N,N))\n",
    "\n",
    "p_ind = ThreeWise(N,h,J,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4, 0.4, 0.4, 0.4]),\n",
       " array([[0.  , 0.16, 0.16, 0.16],\n",
       "        [0.  , 0.  , 0.16, 0.16],\n",
       "        [0.  , 0.  , 0.  , 0.16],\n",
       "        [0.  , 0.  , 0.  , 0.  ]]),\n",
       " array([[[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.064, 0.064],\n",
       "         [0.   , 0.   , 0.   , 0.064],\n",
       "         [0.   , 0.   , 0.   , 0.   ]],\n",
       " \n",
       "        [[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.064],\n",
       "         [0.   , 0.   , 0.   , 0.   ]],\n",
       " \n",
       "        [[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ]],\n",
       " \n",
       "        [[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ]]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.22044605e-16, 2.22044605e-16],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22044605e-16],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22044605e-16],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statistics(p_ind) #produces expected stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now randomly instantiate 3-wise models of different sizes $N$ and then fit independent and pairwise models to the averages and pairwise correlations produced by the 3-wise models. At each size, we measure the true KL divergences between the 3-wise model and the independent and pairwise models. We also calculate the KL divergences based on the perturbative results. Finally, we compare the true distances and the distances predicted by the perturbative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_divergences(N,verb=True):\n",
    "    # fit true distribution\n",
    "    p_true = sim_p_true(N)\n",
    "    avgs_t, corrs_2_t, corrs_3_t, rho_t, rho_b_t = get_statistics(p_true) # get stats\n",
    "\n",
    "    # fit independent model - set h to -ln(1/avgs_t - 1) and all other params to 0\n",
    "    p_ind = ThreeWise(N,-np.log(1/avgs_t - 1),np.zeros((N,N)),np.zeros((N,N,N)))\n",
    "\n",
    "    # fit pairwise distribution\n",
    "    p_pair = Ising(N, avgs_t, corrs_2_t, lr=0.5) \n",
    "\n",
    "    def dist(avgs, corrs, p): # Calcs how far the pairwise models averages and correlations are from the true ones\n",
    "        m_av = np.mean(avgs) # roughly normalise differences before taking the norm\n",
    "        m_cor = np.mean(corrs)\n",
    "        return np.linalg.norm((avgs-p.averages())/m_av, 1) + np.linalg.norm( (corrs-p.correlations())/m_cor,1) \n",
    "\n",
    "    d=dist(avgs_t, corrs_2_t, p_pair)\n",
    "    if verb: print(f\"Progress, N={N}:\")\n",
    "    while d > 0.5:\n",
    "        p_pair.gradient_ascent()\n",
    "        d=dist(avgs_t, corrs_2_t, p_pair)\n",
    "        if verb: print(round(d,1),end=\" \")\n",
    "\n",
    "    if verb: print()\n",
    "    avgs_p, corrs_2_p, corrs_3_p, rho_p, rho_b_p = get_statistics(p_pair) # get stats\n",
    "    \n",
    "    if verb:\n",
    "        print(\"True stats\")\n",
    "        print(avgs_t,corrs_2_t, sep=\"\\n\")\n",
    "        print(\"Pairwise stats\")\n",
    "        print(avgs_p,corrs_2_p, sep=\"\\n\")\n",
    "\n",
    "    # calc. actual and perturbative KL divergences\n",
    "    def D_KL(p,q):\n",
    "        d = 0\n",
    "        for s in p.states:\n",
    "            d += p.p(s)*np.log(p.p(s)/q.p(s))\n",
    "        return d\n",
    "    D_KL_pair = D_KL(p_true, p_pair)\n",
    "    D_KL_ind = D_KL(p_true, p_ind)\n",
    "\n",
    "    # pert. divergences\n",
    "    PD_KL_pair = 0\n",
    "    for i in range(N-2):\n",
    "        for j in range(i+1,N-1):\n",
    "            for k in range(j+1,N):\n",
    "                PD_KL_pair+=avgs_p[i]*avgs_p[j]*avgs_p[k]*f(rho_b_t[i,j,k], rho_b_p[i,j,k])\n",
    "\n",
    "    PD_KL_pair/=np.log(2)\n",
    "\n",
    "    PD_KL_ind = 0\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1,N):\n",
    "            PD_KL_ind+=avgs_p[i]*avgs_p[j]*f(rho_t[i,j], 0)\n",
    "\n",
    "    PD_KL_ind/=np.log(2)\n",
    "    \n",
    "    if verb:\n",
    "        print(\"Comparison:\")\n",
    "        print(D_KL_pair,PD_KL_pair)\n",
    "        print(D_KL_ind,PD_KL_ind)\n",
    "    \n",
    "    return D_KL_pair, D_KL_ind, PD_KL_pair, PD_KL_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress, N=3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.4 27.8 27.3 26.8 26.4 26.1 25.8 25.5 25.2 24.9 24.6 24.3 24.1 23.8 23.6 23.3 23.1 22.9 22.6 22.4 22.2 22.0 21.8 21.6 21.4 21.2 21.0 20.8 20.6 20.4 20.2 20.1 19.9 19.7 19.5 19.4 19.2 19.1 18.9 18.7 18.6 18.4 18.3 18.1 18.0 17.9 17.7 17.6 17.4 17.3 17.2 17.0 16.9 16.8 16.7 16.5 16.4 16.3 16.2 16.1 16.0 15.8 15.7 15.6 15.5 15.4 15.3 15.2 15.1 15.0 14.9 14.8 14.7 14.6 14.5 14.4 14.3 14.2 14.1 14.0 14.0 13.9 13.8 13.7 13.6 13.5 13.4 13.4 13.3 13.2 13.1 13.0 13.0 12.9 12.8 12.7 12.7 12.6 12.5 12.5 12.4 12.3 12.2 12.2 12.1 12.0 12.0 11.9 11.8 11.8 11.7 11.7 11.6 11.5 11.5 11.4 11.3 11.3 11.2 11.2 11.1 11.1 11.0 10.9 10.9 10.8 10.8 10.7 10.7 10.6 10.6 10.5 10.5 10.4 10.4 10.3 10.3 10.2 10.2 10.1 10.1 10.0 10.0 9.9 9.9 9.8 9.8 9.7 9.7 9.7 9.6 9.6 9.5 9.5 9.4 9.4 9.4 9.3 9.3 9.2 9.2 9.2 9.1 9.1 9.0 9.0 9.0 8.9 8.9 8.9 8.8 8.8 8.7 8.7 8.7 8.6 8.6 8.6 8.5 8.5 8.5 8.4 8.4 8.4 8.3 8.3 8.3 8.2 8.2 8.2 8.1 8.1 8.1 8.0 8.0 8.0 7.9 7.9 7.9 7.8 7.8 7.8 7.8 7.7 7.7 7.7 7.6 7.6 7.6 7.6 7.5 7.5 7.5 7.5 7.4 7.4 7.4 7.3 7.3 7.3 7.3 7.2 7.2 7.2 7.2 7.1 7.1 7.1 7.1 7.0 7.0 7.0 7.0 6.9 6.9 6.9 6.9 6.8 6.8 6.8 6.8 6.8 6.7 6.7 6.7 6.7 6.6 6.6 6.6 6.6 6.6 6.5 6.5 6.5 6.5 6.5 6.4 6.4 6.4 6.4 6.4 6.3 6.3 6.3 6.3 6.3 6.2 6.2 6.2 6.2 6.2 6.1 6.1 6.1 6.1 6.1 6.0 6.0 6.0 6.0 6.0 5.9 5.9 5.9 5.9 5.9 5.9 5.8 5.8 5.8 5.8 5.8 5.8 5.7 5.7 5.7 5.7 5.7 5.7 5.6 5.6 5.6 5.6 5.6 5.6 5.5 5.5 5.5 5.5 5.5 5.5 5.5 5.4 5.4 5.4 5.4 5.4 5.4 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.2 5.2 5.2 5.2 5.2 5.2 5.2 5.1 5.1 5.1 5.1 5.1 5.1 5.1 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 4.9 4.9 4.9 4.9 4.9 4.9 4.9 4.9 4.8 4.8 4.8 4.8 4.8 4.8 4.8 4.8 4.7 4.7 4.7 4.7 4.7 4.7 4.7 4.7 4.6 4.6 4.6 4.6 4.6 4.6 4.6 4.6 4.6 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.4 4.4 4.4 4.4 4.4 4.4 4.4 4.4 4.4 4.4 4.3 4.3 4.3 4.3 4.3 4.3 4.3 4.3 4.3 4.3 4.2 4.2 4.2 4.2 4.2 4.2 4.2 4.2 4.2 4.2 4.1 4.1 4.1 4.1 4.1 4.1 4.1 4.1 4.1 4.1 4.1 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 3.9 3.9 3.9 3.9 3.9 3.9 3.9 3.9 3.9 3.9 3.9 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.8 3.7 3.7 3.7 3.7 3.7 3.7 3.7 3.7 3.7 3.7 3.7 3.7 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.5 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.01746343 0.00195421 0.00589742]\n",
      "[[0.00000000e+00 4.77045438e-05 2.77236163e-05]\n",
      " [0.00000000e+00 0.00000000e+00 4.96913997e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Pairwise stats\n",
      "[0.01746343 0.0019542  0.00589741]\n",
      "[[0.00000000e+00 4.76671026e-05 2.88813315e-05]\n",
      " [0.00000000e+00 0.00000000e+00 8.27529507e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Comparison:\n",
      "8.023196497135388e-07 8.980313938606414e-10\n",
      "4.434882125701405e-05 6.298590269336494e-05\n",
      "Progress, N=3:\n",
      "1.5 1.4 1.3 1.2 1.1 1.0 0.9 0.8 0.8 0.7 0.6 0.6 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.01875023 0.02626194 0.0643203 ]\n",
      "[[0.         0.00048409 0.00110224]\n",
      " [0.         0.         0.00411659]\n",
      " [0.         0.         0.        ]]\n",
      "Pairwise stats\n",
      "[0.01871805 0.02626041 0.06431749]\n",
      "[[0.         0.00077057 0.00135327]\n",
      " [0.         0.         0.00407304]\n",
      " [0.         0.         0.        ]]\n",
      "Comparison:\n",
      "8.83735524740981e-05 2.4490972624041275e-05\n",
      "0.0014195404932770468 0.0017948836459903718\n",
      "Progress, N=3:\n",
      "2.4 2.2 2.0 1.8 1.6 1.5 1.3 1.2 1.2 1.1 1.1 1.1 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.03950049 0.02618379 0.01281891]\n",
      "[[0.         0.00337888 0.00073067]\n",
      " [0.         0.         0.00082454]\n",
      " [0.         0.         0.        ]]\n",
      "Pairwise stats\n",
      "[0.03949948 0.02618956 0.0128206 ]\n",
      "[[0.         0.00336615 0.00083513]\n",
      " [0.         0.         0.00065522]\n",
      " [0.         0.         0.        ]]\n",
      "Comparison:\n",
      "3.391344006933149e-05 3.4277757255563426e-06\n",
      "0.00214042352339519 0.002815707470839021\n",
      "Progress, N=4:\n",
      "18.2 17.8 17.5 17.2 17.0 16.7 16.5 16.3 16.0 15.8 15.6 15.4 15.3 15.1 14.9 14.7 14.5 14.4 14.2 14.0 13.9 13.7 13.6 13.4 13.3 13.1 13.0 12.9 12.7 12.6 12.4 12.3 12.2 12.1 11.9 11.8 11.7 11.6 11.5 11.4 11.3 11.1 11.0 10.9 10.8 10.7 10.6 10.5 10.4 10.3 10.2 10.1 10.1 10.0 9.9 9.8 9.7 9.6 9.5 9.4 9.4 9.3 9.2 9.1 9.1 9.0 8.9 8.8 8.8 8.7 8.6 8.5 8.5 8.4 8.3 8.3 8.2 8.1 8.1 8.0 8.0 7.9 7.8 7.8 7.7 7.7 7.6 7.5 7.5 7.4 7.4 7.3 7.3 7.2 7.2 7.1 7.1 7.0 7.0 6.9 6.9 6.8 6.8 6.7 6.7 6.6 6.6 6.5 6.5 6.5 6.4 6.4 6.3 6.3 6.2 6.2 6.2 6.1 6.1 6.1 6.0 6.0 5.9 5.9 5.9 5.8 5.8 5.8 5.7 5.7 5.6 5.6 5.6 5.5 5.5 5.5 5.4 5.4 5.4 5.3 5.3 5.3 5.3 5.2 5.2 5.2 5.1 5.1 5.1 5.0 5.0 5.0 5.0 4.9 4.9 4.9 4.9 4.8 4.8 4.8 4.7 4.7 4.7 4.7 4.6 4.6 4.6 4.6 4.5 4.5 4.5 4.5 4.5 4.4 4.4 4.4 4.4 4.3 4.3 4.3 4.3 4.3 4.2 4.2 4.2 4.2 4.1 4.1 4.1 4.1 4.1 4.0 4.0 4.0 4.0 4.0 4.0 3.9 3.9 3.9 3.9 3.9 3.8 3.8 3.8 3.8 3.8 3.8 3.7 3.7 3.7 3.7 3.7 3.6 3.6 3.6 3.6 3.6 3.6 3.6 3.5 3.5 3.5 3.5 3.5 3.5 3.4 3.4 3.4 3.4 3.4 3.4 3.4 3.3 3.3 3.3 3.3 3.3 3.3 3.3 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.2 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.1 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.9 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.8 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.3 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.00532956 0.00034474 0.0094497  0.03132193]\n",
      "[[0.00000000e+00 2.00533491e-06 4.01164607e-05 1.09702284e-04]\n",
      " [0.00000000e+00 0.00000000e+00 2.49633394e-05 5.83909012e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.48904648e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Pairwise stats\n",
      "[0.00532955 0.00034677 0.00944971 0.03132194]\n",
      "[[0.00000000e+00 2.42631072e-06 4.12861164e-05 1.09988652e-04]\n",
      " [0.00000000e+00 0.00000000e+00 1.41379354e-05 4.77096477e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.49059945e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Comparison:\n",
      "5.283785519111574e-06 8.748979824472729e-07\n",
      "0.00014517510909134744 0.00019858509179391533\n",
      "Progress, N=4:\n",
      "2.8 2.6 2.4 2.2 2.0 1.8 1.7 1.5 1.4 1.3 1.2 1.1 1.0 0.9 0.9 0.8 0.7 0.7 0.6 0.6 0.6 0.5 0.5 \n",
      "True stats\n",
      "[0.04922181 0.00135306 0.04895424 0.03574929]\n",
      "[[0.00000000e+00 1.12318045e-04 4.27317010e-03 1.34161649e-03]\n",
      " [0.00000000e+00 0.00000000e+00 2.54843118e-05 2.70803530e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.67600094e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Pairwise stats\n",
      "[0.04922001 0.00135736 0.04896089 0.03574703]\n",
      "[[0.00000000e+00 7.64026936e-05 4.23622091e-03 1.50244978e-03]\n",
      " [0.00000000e+00 0.00000000e+00 7.19897713e-05 5.77373621e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.61163641e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Comparison:\n",
      "5.474980976358734e-05 1.6415708594339605e-05\n",
      "0.0010048990477667078 0.0012757164956748574\n",
      "Progress, N=4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7 3.1 2.7 2.4 2.2 1.9 1.7 1.6 1.4 1.3 1.3 1.2 1.2 1.2 1.1 1.1 1.1 1.0 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.03234113 0.0475063  0.00230926 0.01261197]\n",
      "[[0.00000000e+00 2.04448439e-03 1.09383840e-04 8.80580070e-04]\n",
      " [0.00000000e+00 0.00000000e+00 9.42754149e-05 3.43469423e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.34299934e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Pairwise stats\n",
      "[0.03234077 0.04750507 0.0023064  0.01260864]\n",
      "[[0.00000000e+00 2.04942515e-03 1.42373267e-04 8.75883470e-04]\n",
      " [0.00000000e+00 0.00000000e+00 1.14522680e-04 4.43566657e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.92909375e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Comparison:\n",
      "2.9011669874285765e-05 2.0210736020993845e-05\n",
      "0.00039362905649152857 0.0005146506995101131\n",
      "Progress, N=5:\n",
      "20.0 18.2 16.9 15.9 15.0 14.2 13.5 12.8 12.2 11.7 11.2 10.7 10.2 9.8 9.4 9.1 8.7 8.4 8.1 7.8 7.5 7.3 7.0 6.8 6.6 6.4 6.2 6.0 5.8 5.6 5.5 5.3 5.2 5.0 4.9 4.8 4.6 4.5 4.4 4.3 4.2 4.1 4.0 3.9 3.8 3.7 3.6 3.5 3.4 3.4 3.3 3.2 3.2 3.1 3.0 3.0 2.9 2.8 2.8 2.7 2.7 2.6 2.6 2.5 2.5 2.4 2.4 2.3 2.3 2.3 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.01759419 0.0156152  0.01159764 0.05213879 0.00219719]\n",
      "[[0.00000000e+00 3.69372391e-04 6.11026270e-04 3.61164845e-04\n",
      "  3.36484932e-05]\n",
      " [0.00000000e+00 0.00000000e+00 3.77564644e-04 1.18715761e-03\n",
      "  1.10821033e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.67783570e-05\n",
      "  1.77548138e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.20091129e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]]\n",
      "Pairwise stats\n",
      "[0.01759415 0.01561524 0.01159772 0.05213873 0.00219784]\n",
      "[[0.00000000e+00 3.69386563e-04 6.10991429e-04 3.61286279e-04\n",
      "  4.77319288e-05]\n",
      " [0.00000000e+00 0.00000000e+00 3.78163936e-04 1.18702590e-03\n",
      "  1.03177284e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.03046752e-04\n",
      "  1.59727910e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.93284775e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]]\n",
      "Comparison:\n",
      "2.7950463218143698e-05 2.25737854768218e-05\n",
      "0.0013485609318666365 0.0018620988411244736\n",
      "Progress, N=5:\n",
      "8.4 7.4 6.5 5.8 5.1 4.5 3.9 3.4 3.0 2.9 2.8 2.7 2.6 2.5 2.4 2.3 2.2 2.1 2.1 2.0 1.9 1.9 1.8 1.7 1.7 1.6 1.6 1.5 1.5 1.5 1.4 1.4 1.3 1.3 1.3 1.2 1.2 1.2 1.1 1.1 1.1 1.1 1.0 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.04869435 0.05966406 0.03177649 0.01254583 0.01065356]\n",
      "[[0.         0.00271766 0.00190242 0.00028607 0.00066171]\n",
      " [0.         0.         0.00480743 0.00045841 0.00081048]\n",
      " [0.         0.         0.         0.00022602 0.00047902]\n",
      " [0.         0.         0.         0.         0.00012335]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "Pairwise stats\n",
      "[0.04869311 0.05966315 0.03177525 0.01253615 0.01064746]\n",
      "[[0.         0.00271781 0.00190381 0.00039241 0.00068261]\n",
      " [0.         0.         0.00480755 0.00052684 0.00083041]\n",
      " [0.         0.         0.         0.00029922 0.00050626]\n",
      " [0.         0.         0.         0.         0.00020537]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "Comparison:\n",
      "0.0002617578509270701 0.00022457052223422166\n",
      "0.0023374070769480544 0.002725769574135287\n",
      "Progress, N=5:\n",
      "32.2 30.2 28.7 27.4 26.3 25.3 24.4 23.6 22.9 22.1 21.5 20.8 20.2 19.7 19.1 18.6 18.1 17.7 17.2 16.8 16.4 16.0 15.6 15.2 14.9 14.5 14.2 13.9 13.6 13.3 13.0 12.8 12.5 12.3 12.0 11.8 11.5 11.3 11.1 10.9 10.7 10.5 10.3 10.1 9.9 9.7 9.6 9.4 9.2 9.1 8.9 8.8 8.6 8.5 8.4 8.2 8.1 8.0 7.8 7.7 7.6 7.5 7.4 7.3 7.1 7.0 6.9 6.8 6.7 6.6 6.5 6.4 6.4 6.3 6.2 6.1 6.0 5.9 5.8 5.8 5.7 5.6 5.5 5.5 5.4 5.3 5.3 5.2 5.1 5.1 5.0 4.9 4.9 4.8 4.8 4.7 4.6 4.6 4.5 4.5 4.4 4.4 4.3 4.3 4.2 4.2 4.1 4.1 4.0 4.0 3.9 3.9 3.9 3.8 3.8 3.7 3.7 3.7 3.6 3.6 3.5 3.5 3.5 3.4 3.4 3.4 3.3 3.3 3.3 3.2 3.2 3.2 3.1 3.1 3.1 3.0 3.0 3.0 3.0 2.9 2.9 2.9 2.9 2.8 2.8 2.8 2.7 2.7 2.7 2.7 2.6 2.6 2.6 2.6 2.6 2.5 2.5 2.5 2.5 2.4 2.4 2.4 2.4 2.4 2.3 2.3 2.3 2.3 2.3 2.3 2.2 2.2 2.2 2.2 2.2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 2.0 2.0 2.0 2.0 2.0 2.0 1.9 1.9 1.9 1.9 1.9 1.9 1.9 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.7 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.6 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.4 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.2 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 \n",
      "True stats\n",
      "[0.00448554 0.01130239 0.00041012 0.04344556 0.00211886]\n",
      "[[0.00000000e+00 2.81933538e-05 9.85424443e-07 1.45466606e-04\n",
      "  4.10700578e-06]\n",
      " [0.00000000e+00 0.00000000e+00 1.83762645e-06 3.47555143e-04\n",
      "  2.28607876e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.06810799e-06\n",
      "  1.81431458e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.47051762e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]]\n",
      "Pairwise stats\n",
      "[0.00448536 0.01130235 0.00040901 0.04344554 0.00211883]\n",
      "[[0.00000000e+00 3.76489872e-05 4.03610950e-06 1.47618796e-04\n",
      "  1.16590916e-05]\n",
      " [0.00000000e+00 0.00000000e+00 5.08479871e-06 3.47579780e-04\n",
      "  2.43930148e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.40402900e-05\n",
      "  1.78512612e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.46911946e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]]\n",
      "Comparison:\n",
      "1.5536783380469812e-05 1.8823223221879662e-06\n",
      "0.00026825966821589773 0.0003589651525210451\n"
     ]
    }
   ],
   "source": [
    "N0 = 3 # starting no. spins\n",
    "Ns = 3 # range of size of spins we consider\n",
    "reps = 3 \n",
    "\n",
    "Store_D_KL_pair = np.zeros((Ns,reps))\n",
    "Store_D_KL_ind = np.zeros_like(Store_D_KL_pair)\n",
    "Store_PD_KL_pair = np.zeros_like(Store_D_KL_pair)\n",
    "Store_PD_KL_ind = np.zeros_like(Store_D_KL_pair)\n",
    "\n",
    "for n in range(Ns):\n",
    "    for i in range(reps):\n",
    "        D_KL_pair, D_KL_ind, PD_KL_pair, PD_KL_ind = get_divergences(N0+n)\n",
    "        Store_D_KL_pair[n,i] = D_KL_pair\n",
    "        Store_D_KL_ind[n,i] = D_KL_ind\n",
    "        Store_PD_KL_pair[n,i] = PD_KL_pair\n",
    "        Store_PD_KL_ind[n,i] = PD_KL_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = Store_D_KL_pair.flatten()\n",
    "x = (np.ones((Ns,reps)).T*np.arange(N0,N0+Ns)).T.flatten()\n",
    "plt.plot(x,y,\"r.\")\n",
    "y = Store_PD_KL_pair.flatten()\n",
    "plt.plot(x,y,\"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = Store_D_KL_ind.flatten()\n",
    "x = (np.ones((Ns,reps)).T*np.arange(N0,N0+Ns)).T.flatten()\n",
    "plt.plot(x,y,\"r.\")\n",
    "y = Store_PD_KL_ind.flatten()\n",
    "plt.plot(x,y,\"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling toy distributions with the pairwise model\n",
    "\n",
    "We consider some toy distributions, one that has all neurons firing or not (\"All or nothing model\"), another which only takes on 2 states (\"A couple of states or nothing model\") and a third where one of the neurons only fires if only one of the other 2 neurons fire (\"XOR\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All or nothing model\n",
    "We start by considering a very simple distribution that has higher order correlations. Let us say we have 5 neurons which always fire in sync. Thus $p(1,1,1,1,1) = c$, $p(0,0,0,0,0)=(1-c)$ and all other events have probability 0. The mean firing rate of individual neurons will be c, as will the correlations. We will vary the probability $c$ of all of them firing, and see whether the pairwise model appears to be a good fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5]\n",
      "[[0.  0.5 0.5 0.5 0.5]\n",
      " [0.  0.  0.5 0.5 0.5]\n",
      " [0.  0.  0.  0.5 0.5]\n",
      " [0.  0.  0.  0.  0.5]\n",
      " [0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "c = 0.5\n",
    "avgs = c*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "corrs = c*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(N, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.53619501 0.53738947 0.54056568 0.54641463 0.55341676]\n",
      "Predicted correlations:\n",
      "[[0.53619501 0.51575932 0.51198993 0.50910874 0.50459316]\n",
      " [0.         0.53738947 0.505844   0.502652   0.49986001]\n",
      " [0.         0.         0.54056568 0.50027544 0.49694551]\n",
      " [0.         0.         0.         0.54641463 0.49396977]\n",
      " [0.         0.         0.         0.         0.55341676]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained a maximum entropy model, let us see what it thinks the true probability distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.] 0.37\n",
      "[1. 1. 1. 1. 1.] 0.46\n"
     ]
    }
   ],
   "source": [
    "for state in [p_wise.states[0],p_wise.states[-1]]:\n",
    "    print(state,np.round(p_wise.p(state),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the pairwise model is able to accurately predict the full probability distribution of the 'all or nothing model' for different values of $c$. I honestly wasn't sure what to expect here, and would be interested in relating this to the results from the Roudi et al. paper. We will have to consider slightly more complex distributions to 'break' the pairwise model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple of states or nothing\n",
    "The next model that came to mind that takes on two states:\n",
    "\n",
    "- $p(0,1,1,1,1)=a$\n",
    "- $p(1,1,1,1,0)=b$\n",
    "- $p(0,0,0,0,0)=1-(a+b)$\n",
    "\n",
    "We define $a+b \\doteq c$\n",
    "\n",
    "The expectation of the neurons will be: \n",
    "\n",
    "    (b, c, c, c, c, a)\n",
    "\n",
    "The pairwise correlations will be:\n",
    "\n",
    "        1 2 3 4 5\n",
    "      1   b b b 0\n",
    "      2     c c a    \n",
    "      3       c a\n",
    "      4         a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.6 0.6 0.6 0.2]\n",
      "[[0.  0.4 0.4 0.4 0. ]\n",
      " [0.  0.  0.6 0.6 0.2]\n",
      " [0.  0.  0.  0.6 0.2]\n",
      " [0.  0.  0.  0.  0.2]]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "a = 0.2\n",
    "b = 0.4\n",
    "c = a + b\n",
    "avgs = np.array([b, c, c, c, a])\n",
    "corrs = np.array([[0,b,b,b,0],\n",
    "                  [0,0,c,c,a],\n",
    "                  [0,0,0,c,a],\n",
    "                  [0,0,0,0,a]])\n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(N, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.40120964 0.60166855 0.60201396 0.60243361 0.20180175]\n",
      "Predicted correlations:\n",
      "[[0.40120964 0.40017571 0.40004125 0.39989105 0.00277631]\n",
      " [0.         0.60166855 0.60019171 0.59988656 0.19942072]\n",
      " [0.         0.         0.60201396 0.59956424 0.19928799]\n",
      " [0.         0.         0.         0.60243361 0.19916612]\n",
      " [0.         0.         0.         0.         0.20180175]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.] 0.392\n",
      "[0. 0. 0. 0. 1.] 0.002\n",
      "[0. 0. 0. 1. 0.] 0.002\n",
      "[0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 0. 0.] 0.001\n",
      "[0. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1.] 0.001\n",
      "[0. 1. 1. 1. 0.] 0.004\n",
      "[0. 1. 1. 1. 1.] 0.196\n",
      "[1. 0. 0. 0. 0.] 0.001\n",
      "[1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 1.] 0.0\n",
      "[1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0.] 0.001\n",
      "[1. 1. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0.] 0.396\n",
      "[1. 1. 1. 1. 1.] 0.003\n"
     ]
    }
   ],
   "source": [
    "for state in p_wise.states:\n",
    "    print(state,np.round(p_wise.p(state),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the pairwise model is able to capture the probability distribution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR \n",
    "\n",
    "In the 2003 Schneidman paper, *Network Information and Connected Correlations*, they say,\n",
    "\n",
    "> If $\\sigma_3$ is formed as the exclusive OR (XOR) of the variables $\\sigma_1$ and $\\sigma_2$, then the essential structure of $p(\\sigma_1,\\sigma_2,\\sigma_3)$ is contained in a three–spin interaction. \n",
    "\n",
    "This might give us a simple example of something the ising model can't model.\n",
    "\n",
    "Let us say that $\\sigma_1$ and $\\sigma_2$ firing independently with probabilities $p(\\sigma_1{=}1)=a$ and $p(\\sigma_2{=}1)=b$. \n",
    "\n",
    "        s_1 s_2 s_3  p(s_1, s_2, s_3)\n",
    "        0   0   0    (1-a)(1-b)\n",
    "        0   1   1    (1-a)b\n",
    "        1   0   1    a(1-b)\n",
    "        1   1   0    ab\n",
    "Thus, the averages are:\n",
    "\n",
    "        (a, b, b+a-2ab)\n",
    "\n",
    "And the correlations are:\n",
    "\n",
    "        s_1 s_2, s_1 s_3, s_2,s_3\n",
    "        ab       a(1-b)   (1-a)b        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2  0.4  0.44]\n",
      "[[0.   0.08 0.12]\n",
      " [0.   0.   0.32]]\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "a = 0.2\n",
    "b = 0.4\n",
    "avgs = np.array([a,b,b+a-2*a*b])\n",
    "corrs = np.array([[0,a*b,a*(1-b)],\n",
    "                  [0,0,(1-a)*b]])\n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(3, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.20000128 0.40000042 0.44000421]\n",
      "Predicted correlations:\n",
      "[[0.20000128 0.08000851 0.11999224]\n",
      " [0.         0.40000042 0.31999632]\n",
      " [0.         0.         0.44000421]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.] 0.406\n",
      "[0. 0. 1.] 0.074\n",
      "[0. 1. 0.] 0.074\n",
      "[0. 1. 1.] 0.246\n",
      "[1. 0. 0.] 0.074\n",
      "[1. 0. 1.] 0.046\n",
      "[1. 1. 0.] 0.006\n",
      "[1. 1. 1.] 0.074\n"
     ]
    }
   ],
   "source": [
    "for state in p_wise.states:\n",
    "    print(state,np.round(p_wise.p(state),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] 0.48\n",
      "[0, 1, 1] 0.32000000000000006\n",
      "[1, 0, 1] 0.12\n",
      "[1, 1, 0] 0.08000000000000002\n"
     ]
    }
   ],
   "source": [
    "print([0,0,0], (1-a)*(1-b))\n",
    "print([0,1,1], (1-a)*b)\n",
    "print([1,0,1], a*(1-b))\n",
    "print([1,1,0], a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the events `[0,0,1]` and `[1,1,1]` are assigned non-zero probabilities, when they should in fact be zero. In general, we can see the predictions are far off. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python39264bit3926084c7cc7f3d4f4391856d584bc48b87"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
