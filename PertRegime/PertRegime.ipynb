{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are we just in the perturbative regime?\n",
    "\n",
    "In the 2009 paper [Pairwise Maximum Entropy Models for Studying Large Biological Systems: When They Can Work and When They Can't](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000380), Roudi et al. suggest that when we are in the perturbative regime, characterised by a small mean probability of observing neurons spike and small number of neurons $N$, the pairwise maxent model can appear to be a good model for a distribution. However, we cannot extrapolate the behaviour of the pairwise model to larger $N$, and predict that it will remain a good fit outside of the perturbative regime. In short:\n",
    "\n",
    "> The distance between the pairwise model and **any** probability distribution appears linear in $N\\bar{v}\\delta t$ in the perturbative regime \n",
    "\n",
    "We try and investigate these claims computationally.\n",
    "\n",
    "The perturbative regime is defined as $N\\bar{v}\\delta t \\ll 1$, where $\\bar{v}$ is the mean firing rate and $\\delta t$ is the size of the time bin. As shorthand, we define $\\delta \\doteq \\bar{v}\\delta t$.  For sufficiently small time bins where we observe at most one spike within each bin, and we can identify $\\delta$ with the mean probability of observing a neuron fire. \n",
    "\n",
    "As an example, for $N=5$ neurons, we should be in the perturbative regime with $\\bar{p}(r_i=1)=\\delta \\ll 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./plotstyle.mplstyle')\n",
    "\n",
    "from scipy import stats\n",
    "from MaxEnt import ThreeWise, Ising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try and reproduce the main computational results in the paper. These results show close agreement between the true distance measure between the 'pairwise' and a '3-wise distribution', and an estimate of the distance measure between these distributions, whilst in the perturbative regime. \n",
    "\n",
    "First, we create a '3-wise distribution'. More accurately, we define the interactions in a model that includes up to 3-wise interactions, which creates a distribution that cannot be explained by a model that includes only up to pairwise interactions. \n",
    "\n",
    "This distribution takes the form:\n",
    "$$\n",
    "    P^{(3)}(\\{r_i\\}) = \\frac{1}{Z} \\exp \\left[ \\sum_i h_i r + \\sum_{i< j} J_{ij}r_i r_j  + \\sum_{i<j<k} K_{ijk}r_i r_j r_k  \\right]\n",
    "$$\n",
    "From the paper, the interaction terms were determined as:\n",
    "- $h_i = - \\ln (1/r_i^* - 1)$, where each $r_i^*$ is randomly drawn from an exponential distribution with mean 0.02\n",
    "- $J_{ij}$ is drawn from a Gaussian distribution with mean 0.05 and s.d. 0.8\n",
    "- $K_{ijk}$ is drawn from a Gaussian distribution with mean 0.02 and s.d. 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_p_true(N,r=0.02, h=None, J=None, K=None):\n",
    "    \"\"\"\n",
    "    Function that creates a distribution that includes up to 3-wise interactions,\n",
    "    by randomly sampling the interaction weights from the distributions specified in the paper if h,J,K set to None\n",
    "    Otherwise, uses the provided interactions parameters.\n",
    "    \"\"\"\n",
    "    if not isinstance(h,np.ndarray):\n",
    "        h = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            h[i] = -np.log(1/np.random.exponential(r) - 1)\n",
    "    \n",
    "    if not isinstance(J,np.ndarray):  \n",
    "        J = np.zeros((N,N))\n",
    "        for i in range(N-1):\n",
    "            for j in range(i+1,N):\n",
    "                J[i,j] = np.random.normal(0.05, 0.8)\n",
    "    \n",
    "    if not isinstance(K,np.ndarray):\n",
    "        K = np.zeros((N,N,N))\n",
    "        for i in range(N-2):\n",
    "            for j in range(i+1,N-1):\n",
    "                for k in range(j+1,N):\n",
    "                    K[i,j,k] = np.random.normal(0.02, 0.5)\n",
    "    \n",
    "    p_true = ThreeWise(N, h, J, K)\n",
    "    return p_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between 0,1,2\n",
      " 3.7889897660635793e-07\n",
      "Correlation between 0,1,3\n",
      " 1.0379457390642611e-07\n",
      "Correlation between 0,2,3\n",
      " 5.251787359703574e-09\n",
      "Correlation between 1,2,3\n",
      " 2.0101177536562e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00021493, 0.04243176, 0.00419708, 0.00735543])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_true = sim_p_true(4,0.02)\n",
    "#calc 3 wise correlations\n",
    "for i in range(p_true.N-2):\n",
    "    for j in range(i+1,p_true.N-1):\n",
    "        for k in range(j+1, p_true.N):\n",
    "            print(f\"Correlation between {i},{j},{k}\\n\",p_true.expectation(lambda s: s[:,i]*s[:,j]*s[:,k]))\n",
    "p_true.averages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main results in the paper are, in the perturbative regime:\n",
    "- $\\Delta_N = D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {pair }}\\right) / D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {ind }}\\right)$ scales as $(N-2)\\delta + \\mathcal{O}\\left((N \\delta)^{2}\\right)$ (I assume the power of 2 is just a safe upper bound). \n",
    "- $$D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {pair }}\\right)=\\frac{1}{\\ln 2} \\sum_{i<j<k} \\bar{r}_{i} \\bar{r}_{j} \\bar{r}_{k} f\\left(\\bar{\\boldsymbol{\\rho}}_{ijk}^{\\text{true}}, \\bar{\\boldsymbol{\\rho}}_{i j k}^{\\text{pair}}\\right)+\\mathcal{O}\\left((N \\delta)^{4}\\right)$$\n",
    "- $$D_{K L}\\left(p_{\\text {true }} \\| p_{\\text {ind }}\\right)=\\frac{1}{\\ln 2} \\sum_{i<j} \\bar{r}_{i} \\bar{r}_{j} f\\left(\\rho_{i j}^{\\text{true}}, 0\\right)+\\mathcal{O}\\left((N \\delta)^{3}\\right)$$\n",
    "\n",
    "The KL divergence is defined as $D_{KL}(p\\| q) \\doteq \\sum_s p_s \\log_2 (p_s/q_s) $, where we sum over all states $s$. $f(x,y) \\doteq (1+x)\\big[\\ln(1+x)-\\ln(1+y)\\big] - (x-y)$, $\\overline{r}_i = \\langle r \\rangle $ (they use $r$ instead of $\\sigma$ in the paper), $\\rho_{ij}$ is the normalised pairwise correlation defined as:\n",
    "$$\n",
    "    \\rho_{ij} \\doteq \\frac{\\langle r_i r_j \\rangle - \\bar{r_i} \\bar{r_j}}{\\bar{r_i} \\bar{r_j}}\n",
    "$$\n",
    "and $\\bar{\\boldsymbol{\\rho}}_{i j k}^{p}$ is defined as:\n",
    "$$\n",
    "    \\bar{\\boldsymbol{\\rho}}_{i j k}^{p} \\doteq \\frac{\\langle r_i r_j r_k \\rangle - \\bar{r_i} \\bar{r_j} \\bar{r_k}}{\\bar{r_i} \\bar{r_j} \\bar{r_k}}\n",
    "$$\n",
    "Note, $\\bar{\\boldsymbol{\\rho}}_{i j k}^{p}$ depends on the distribution $p$ that is used to calculate the expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(p):\n",
    "    avgs = p.averages() #get the averages \\bar{r}\n",
    "    corrs_2 = p.correlations() #get the pairwise correlations <r_i r_j>\n",
    "    \n",
    "    N = p.N #how many neurons\n",
    "    \n",
    "    #calc all the \\rho_{ij}\n",
    "    rho = np.zeros((N,N))\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1,N):\n",
    "            rho[i,j]= corrs_2[i,j]/(avgs[i]*avgs[j]) - 1\n",
    "            \n",
    "    #calc all the \\bar{\\rho}_{ijk}\n",
    "    rho_b = np.zeros((N,N,N))\n",
    "    corrs_3 = np.zeros((N,N,N))\n",
    "    for i in range(N-2):\n",
    "        for j in range(i+1,N-1):\n",
    "            for k in range(j+1,N):\n",
    "                corrs_3[i,j,k]= p.expectation(lambda s: s[:,i]*s[:,j]*s[:,k])\n",
    "                rho_b[i,j,k] = corrs_3[i,j,k] / (avgs[i]*avgs[j]*avgs[k]) - 1\n",
    "                \n",
    "    return avgs, corrs_2, corrs_3, rho, rho_b\n",
    "\n",
    "def f(x,y):\n",
    "    return (1+x)*(np.log(1+x) - np.log(1+y)) - (x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test all of this out, let's define a model that models the probability of each neuron firing as being independent. This corresponds to setting the 'local fields' $h_i$ to $\\ln(\\bar{r}_i/(1-\\bar{r}_i))$, and all other interaction parameters to 0. The expectations $\\langle r_i r_j ... r_p \\rangle$ should purely be products of the expectations of seeing indivdual neurons fire $\\bar{r}_i \\bar{r}_j ... \\bar{r}_p$. Hence, the normalised correlations should all be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "r_bar = np.ones(N)*0.4\n",
    "h = -np.log(1/r_bar - 1)\n",
    "J = np.zeros((N,N))\n",
    "K = np.zeros((N,N,N))\n",
    "\n",
    "p_ind = ThreeWise(N,h,J,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4, 0.4, 0.4, 0.4]),\n",
       " array([[0.  , 0.16, 0.16, 0.16],\n",
       "        [0.  , 0.  , 0.16, 0.16],\n",
       "        [0.  , 0.  , 0.  , 0.16],\n",
       "        [0.  , 0.  , 0.  , 0.  ]]),\n",
       " array([[[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.064, 0.064],\n",
       "         [0.   , 0.   , 0.   , 0.064],\n",
       "         [0.   , 0.   , 0.   , 0.   ]],\n",
       " \n",
       "        [[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.064],\n",
       "         [0.   , 0.   , 0.   , 0.   ]],\n",
       " \n",
       "        [[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ]],\n",
       " \n",
       "        [[0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ],\n",
       "         [0.   , 0.   , 0.   , 0.   ]]]),\n",
       " array([[0.00000000e+00, 2.22044605e-16, 2.22044605e-16, 2.22044605e-16],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.22044605e-16, 2.22044605e-16],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22044605e-16],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       " array([[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.22044605e-16, 2.22044605e-16],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22044605e-16],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22044605e-16],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_statistics(p_ind) #produces expected stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now randomly instantiate 3-wise models of different sizes $N$ and then fit independent and pairwise models to the averages and pairwise correlations produced by the 3-wise models. At each size, we measure the true KL divergences between the 3-wise model and the independent and pairwise models. We also calculate the KL divergences based on the perturbative results. Finally, we compare the true distances and the distances predicted by the perturbative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_divergences(N,verb=True,max_its=5000,K=None):\n",
    "    # fit true distribution\n",
    "    p_true = sim_p_true(N,K=K)\n",
    "    avgs_t, corrs_2_t, corrs_3_t, rho_t, rho_b_t = get_statistics(p_true) # get stats\n",
    "\n",
    "    # fit independent model - set h to -ln(1/avgs_t - 1) and all other params to 0\n",
    "    p_ind = ThreeWise(N,-np.log(1/avgs_t - 1),np.zeros((N,N)),np.zeros((N,N,N)))\n",
    "\n",
    "    # fit pairwise distribution\n",
    "    p_pair = Ising(N, avgs_t, corrs_2_t, lr=0.5) \n",
    "\n",
    "    # define a notion of distance between the pairwise and true distribution and train \n",
    "    \n",
    "    def dist(corrs, p): # Calcs how far the pairwise model's correlations are from the true ones\n",
    "        m_cor = np.mean(corrs)\n",
    "        return np.linalg.norm(corrs-p.correlations(),1) \n",
    "\n",
    "    d=dist(corrs_2_t, p_pair)\n",
    "    if verb: print(f\"Progress, N={N}:\")\n",
    "    \n",
    "    i = 0\n",
    "    while d > 1e-6 and i < max_its: \n",
    "        p_pair.gradient_ascent()\n",
    "        d=dist(corrs_2_t, p_pair)\n",
    "        if verb and i%50==0: print(i,end=\" \")\n",
    "        i+=1\n",
    "\n",
    "    if verb: print()\n",
    "\n",
    "    # model is now trained\n",
    "    \n",
    "    avgs_p, corrs_2_p, corrs_3_p, rho_p, rho_b_p = get_statistics(p_pair) # get stats\n",
    "    \n",
    "    if verb:\n",
    "        print(\"True stats\")\n",
    "        print(avgs_t,corrs_2_t, sep=\"\\n\")\n",
    "        print(\"Pairwise stats\")\n",
    "        print(avgs_p,corrs_2_p, sep=\"\\n\")\n",
    "\n",
    "    # calc. actual and perturbative KL divergences\n",
    "    def D_KL(p,q):\n",
    "        return np.sum(p.p(p.states)*np.log(p.p(p.states)/q.p(p.states)))\n",
    "    \n",
    "    D_KL_pair = D_KL(p_true, p_pair)\n",
    "    D_KL_ind = D_KL(p_true, p_ind)\n",
    "\n",
    "    # pert. divergence between true and pairwise model\n",
    "    PD_KL_pair = 0\n",
    "    for i in range(N-2):\n",
    "        for j in range(i+1,N-1):\n",
    "            for k in range(j+1,N):\n",
    "                PD_KL_pair+=avgs_t[i]*avgs_t[j]*avgs_t[k]*f(rho_b_t[i,j,k], rho_b_p[i,j,k])\n",
    "\n",
    "    PD_KL_pair/=np.log(2)\n",
    "\n",
    "    # pert. divergence between true and independent model\n",
    "    PD_KL_ind = 0\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1,N):\n",
    "            PD_KL_ind+=avgs_t[i]*avgs_t[j]*f(rho_t[i,j], 0)\n",
    "\n",
    "    PD_KL_ind/=np.log(2)\n",
    "    \n",
    "    if verb:\n",
    "        print(\"Comparison:\")\n",
    "        print(D_KL_pair,PD_KL_pair)\n",
    "        print(D_KL_ind,PD_KL_ind)\n",
    "    \n",
    "    return D_KL_pair, D_KL_ind, PD_KL_pair, PD_KL_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress, N=3:\n",
      "0 50 \n",
      "True stats\n",
      "[0.01798593 0.05503321 0.03898546]\n",
      "[[0.         0.00161615 0.00020953]\n",
      " [0.         0.         0.00208706]\n",
      " [0.         0.         0.        ]]\n",
      "Pairwise stats\n",
      "[0.01798592 0.05503321 0.03898545]\n",
      "[[0.         0.00161615 0.00021048]\n",
      " [0.         0.         0.00208706]\n",
      " [0.         0.         0.        ]]\n",
      "Comparison:\n",
      "1.8587185719482663e-06 2.3010446912676574e-06\n",
      "0.0004326326235385165 0.0005848730696096324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.8587185719482663e-06,\n",
       " 0.0004326326235385165,\n",
       " 2.3010446912676574e-06,\n",
       " 0.0005848730696096324)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_divergences(3,verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 4\n",
      "Repetition: 9\n",
      "Repetition: 19\n",
      "Repetition: 29\n",
      "Repetition: 39\n",
      "Repetition: 49\n",
      "Repetition: 59\n",
      "Repetition: 69\n",
      "Repetition: 79\n",
      "Repetition: 89\n",
      "Repetition: 99\n",
      "Size: 5\n",
      "Repetition: 9\n",
      "Repetition: 19\n",
      "Repetition: 29\n",
      "Repetition: 39\n",
      "Repetition: 49\n",
      "Repetition: 59\n",
      "Repetition: 69\n",
      "Repetition: 79\n",
      "Repetition: 89\n",
      "Repetition: 99\n",
      "Size: 6\n",
      "Repetition: 9\n",
      "Repetition: 19\n",
      "Repetition: 29\n",
      "Repetition: 39\n",
      "Repetition: 49\n",
      "Repetition: 59\n",
      "Repetition: 69\n",
      "Repetition: 79\n",
      "Repetition: 89\n",
      "Repetition: 99\n",
      "Size: 7\n",
      "Repetition: 9\n",
      "Repetition: 19\n",
      "Repetition: 29\n",
      "Repetition: 39\n",
      "Repetition: 49\n",
      "Repetition: 59\n"
     ]
    }
   ],
   "source": [
    "N0 = 4 # starting no. spins\n",
    "Ns = 5 # range of size of spins we consider\n",
    "reps = 100 # number of times we repeat each trial (should do all of this in parallel) \n",
    "\n",
    "Store_D_KL_pair = np.zeros((Ns,reps))\n",
    "Store_D_KL_ind = np.zeros_like(Store_D_KL_pair)\n",
    "Store_PD_KL_pair = np.zeros_like(Store_D_KL_pair)\n",
    "Store_PD_KL_ind = np.zeros_like(Store_D_KL_pair)\n",
    "\n",
    "for n in range(Ns):\n",
    "    print(\"Size:\",N0+n)\n",
    "    for i in range(reps):\n",
    "        if not (i+1)%10: print(\"Repetition:\",i)\n",
    "        D_KL_pair, D_KL_ind, PD_KL_pair, PD_KL_ind = get_divergences(N0+n,verb=False)\n",
    "        Store_D_KL_pair[n,i] = D_KL_pair\n",
    "        Store_D_KL_ind[n,i] = D_KL_ind\n",
    "        Store_PD_KL_pair[n,i] = PD_KL_pair\n",
    "        Store_PD_KL_ind[n,i] = PD_KL_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "We plot the difference between predicted KL-divergences and the actual KL-divergences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_averages(D, N0=4,reps=10, colour=\"black\"):\n",
    "    Ns = np.arange(N0,N0+len(D))\n",
    "    avgs = np.mean(D,1)\n",
    "    stds = np.std(D,1)\n",
    "    t=stats.t.ppf(1-0.025, df=reps-1) #t-val for 95% confidence interval around mean\n",
    "    plt.plot(Ns, avgs, \".\", color=colour)\n",
    "    plt.plot(Ns, avgs+t*stds/np.sqrt(reps), \"_\", color=colour)\n",
    "    plt.plot(Ns, avgs-t*stds/np.sqrt(reps), \"_\", color=colour)\n",
    "    plt.xticks(Ns)\n",
    "    \n",
    "    return (avgs, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_averages(Store_D_KL_pair)\n",
    "plot_averages(Store_PD_KL_pair,colour=\"red\")\n",
    "plt.title(\"Perturbative vs. actual KL divergence\")\n",
    "plt.xlabel(\"System size\")\n",
    "plt.ylabel(\"$D_{KL}$(True, Pairwise)\",rotation=0, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_averages(Store_D_KL_ind)\n",
    "plot_averages(Store_PD_KL_ind,colour=\"red\")\n",
    "plt.title(\"Perturbative vs. actual KL divergence\")\n",
    "plt.xlabel(\"System size\")\n",
    "plt.ylabel(\"$D_{KL}$(True, Independent)\",rotation=0, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see if the pairwise model is able to model the distribution? For instance, if the true model is itself a pairwise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 4\n",
      "Repetition: 0\n",
      "Repetition: 1\n",
      "Repetition: 2\n",
      "Size: 5\n",
      "Repetition: 0\n",
      "Repetition: 1\n",
      "Repetition: 2\n",
      "Size: 6\n",
      "Repetition: 0\n",
      "Repetition: 1\n",
      "Repetition: 2\n"
     ]
    }
   ],
   "source": [
    "N0 = 4 # starting no. spins\n",
    "Ns = 3 # range of size of spins we consider\n",
    "reps = 3 # number of times we repeat each trial (should do all of this in parallel) \n",
    "\n",
    "Store_D_KL_pair = np.zeros((Ns,reps))\n",
    "Store_D_KL_ind = np.zeros_like(Store_D_KL_pair)\n",
    "Store_PD_KL_pair = np.zeros_like(Store_D_KL_pair)\n",
    "Store_PD_KL_ind = np.zeros_like(Store_D_KL_pair)\n",
    "\n",
    "for n in range(Ns):\n",
    "    N = N0+n\n",
    "    print(\"Size:\",N)\n",
    "    for i in range(reps):\n",
    "        print(\"Repetition:\",i)\n",
    "        D_KL_pair, D_KL_ind, PD_KL_pair, PD_KL_ind = get_divergences(N,verb=False,K=np.zeros((N,N,N)))\n",
    "        Store_D_KL_pair[n,i] = D_KL_pair\n",
    "        Store_D_KL_ind[n,i] = D_KL_ind\n",
    "        Store_PD_KL_pair[n,i] = PD_KL_pair\n",
    "        Store_PD_KL_ind[n,i] = PD_KL_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_averages(Store_D_KL_pair)\n",
    "plot_averages(Store_PD_KL_pair,colour=\"red\")\n",
    "plt.title(\"Perturbative vs. actual KL divergence\")\n",
    "plt.xlabel(\"System size\")\n",
    "plt.ylabel(\"$D_{KL}$(True, Pairwise)\",rotation=0, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling toy distributions with the pairwise model\n",
    "\n",
    "We consider some toy distributions, one that has all neurons firing or not (\"All or nothing model\"), another which only takes on 2 states (\"A couple of states or nothing model\") and a third where one of the neurons only fires if only one of the other 2 neurons fire (\"XOR\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All or nothing model\n",
    "We start by considering a very simple distribution that has higher order correlations. Let us say we have 5 neurons which always fire in sync. Thus $p(1,1,1,1,1) = c$, $p(0,0,0,0,0)=(1-c)$ and all other events have probability 0. The mean firing rate of individual neurons will be c, as will the correlations. We will vary the probability $c$ of all of them firing, and see whether the pairwise model appears to be a good fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5]\n",
      "[[0.  0.5 0.5 0.5 0.5]\n",
      " [0.  0.  0.5 0.5 0.5]\n",
      " [0.  0.  0.  0.5 0.5]\n",
      " [0.  0.  0.  0.  0.5]\n",
      " [0.  0.  0.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "c = 0.5\n",
    "avgs = c*np.ones(N) # prob of every neuron firing in a window is 0.5\n",
    "corrs = c*np.triu(np.ones((N,N)),1) # prob of 2 neurons firing in the same window is 0.2 \n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(N, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.53619501 0.53738947 0.54056568 0.54641463 0.55341676]\n",
      "Predicted correlations:\n",
      "[[0.53619501 0.51575932 0.51198993 0.50910874 0.50459316]\n",
      " [0.         0.53738947 0.505844   0.502652   0.49986001]\n",
      " [0.         0.         0.54056568 0.50027544 0.49694551]\n",
      " [0.         0.         0.         0.54641463 0.49396977]\n",
      " [0.         0.         0.         0.         0.55341676]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained a maximum entropy model, let us see what it thinks the true probability distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.] 0.37\n",
      "[1. 1. 1. 1. 1.] 0.46\n"
     ]
    }
   ],
   "source": [
    "for state in [p_wise.states[0],p_wise.states[-1]]:\n",
    "    print(state,np.round(p_wise.p(state),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the pairwise model is able to accurately predict the full probability distribution of the 'all or nothing model' for different values of $c$. I honestly wasn't sure what to expect here, and would be interested in relating this to the results from the Roudi et al. paper. We will have to consider slightly more complex distributions to 'break' the pairwise model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple of states or nothing\n",
    "The next model that came to mind that takes on two states:\n",
    "\n",
    "- $p(0,1,1,1,1)=a$\n",
    "- $p(1,1,1,1,0)=b$\n",
    "- $p(0,0,0,0,0)=1-(a+b)$\n",
    "\n",
    "We define $a+b \\doteq c$\n",
    "\n",
    "The expectation of the neurons will be: \n",
    "\n",
    "    (b, c, c, c, c, a)\n",
    "\n",
    "The pairwise correlations will be:\n",
    "\n",
    "        1 2 3 4 5\n",
    "      1   b b b 0\n",
    "      2     c c a    \n",
    "      3       c a\n",
    "      4         a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.6 0.6 0.6 0.2]\n",
      "[[0.  0.4 0.4 0.4 0. ]\n",
      " [0.  0.  0.6 0.6 0.2]\n",
      " [0.  0.  0.  0.6 0.2]\n",
      " [0.  0.  0.  0.  0.2]]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "a = 0.2\n",
    "b = 0.4\n",
    "c = a + b\n",
    "avgs = np.array([b, c, c, c, a])\n",
    "corrs = np.array([[0,b,b,b,0],\n",
    "                  [0,0,c,c,a],\n",
    "                  [0,0,0,c,a],\n",
    "                  [0,0,0,0,a]])\n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(N, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise.gradient_ascent() # 100 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.40120964 0.60166855 0.60201396 0.60243361 0.20180175]\n",
      "Predicted correlations:\n",
      "[[0.40120964 0.40017571 0.40004125 0.39989105 0.00277631]\n",
      " [0.         0.60166855 0.60019171 0.59988656 0.19942072]\n",
      " [0.         0.         0.60201396 0.59956424 0.19928799]\n",
      " [0.         0.         0.         0.60243361 0.19916612]\n",
      " [0.         0.         0.         0.         0.20180175]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.] 0.392\n",
      "[0. 0. 0. 0. 1.] 0.002\n",
      "[0. 0. 0. 1. 0.] 0.002\n",
      "[0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 0. 0.] 0.001\n",
      "[0. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1.] 0.001\n",
      "[0. 1. 1. 1. 0.] 0.004\n",
      "[0. 1. 1. 1. 1.] 0.196\n",
      "[1. 0. 0. 0. 0.] 0.001\n",
      "[1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 1.] 0.0\n",
      "[1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0.] 0.001\n",
      "[1. 1. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0.] 0.396\n",
      "[1. 1. 1. 1. 1.] 0.003\n"
     ]
    }
   ],
   "source": [
    "for state in p_wise.states:\n",
    "    print(state,np.round(p_wise.p(state),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the pairwise model is able to capture the probability distribution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR \n",
    "\n",
    "In the 2003 Schneidman paper, *Network Information and Connected Correlations*, they say,\n",
    "\n",
    "> If $\\sigma_3$ is formed as the exclusive OR (XOR) of the variables $\\sigma_1$ and $\\sigma_2$, then the essential structure of $p(\\sigma_1,\\sigma_2,\\sigma_3)$ is contained in a threeâ€“spin interaction. \n",
    "\n",
    "This might give us a simple example of something the ising model can't model.\n",
    "\n",
    "Let us say that $\\sigma_1$ and $\\sigma_2$ firing independently with probabilities $p(\\sigma_1{=}1)=a$ and $p(\\sigma_2{=}1)=b$. \n",
    "\n",
    "        s_1 s_2 s_3  p(s_1, s_2, s_3)\n",
    "        0   0   0    (1-a)(1-b)\n",
    "        0   1   1    (1-a)b\n",
    "        1   0   1    a(1-b)\n",
    "        1   1   0    ab\n",
    "Thus, the averages are:\n",
    "\n",
    "        (a, b, b+a-2ab)\n",
    "\n",
    "And the correlations are:\n",
    "\n",
    "        s_1 s_2, s_1 s_3, s_2,s_3\n",
    "        ab       a(1-b)   (1-a)b        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2  0.4  0.44]\n",
      "[[0.   0.08 0.12]\n",
      " [0.   0.   0.32]\n",
      " [0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "a = 0.2\n",
    "b = 0.4\n",
    "avgs = np.array([a,b,b+a-2*a*b])\n",
    "corrs = np.array([[0,a*b,a*(1-b)],\n",
    "                  [0,0,(1-a)*b],\n",
    "                  [0,0,0]])\n",
    "print(avgs,corrs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wise = Ising(3, avgs, corrs, lr=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_wise.gradient_ascent() # 500 steps of gradient ascent. Repeat until accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted averages:\n",
      "[0.2  0.4  0.44]\n",
      "Predicted correlations:\n",
      "[[0.   0.08 0.12]\n",
      " [0.   0.   0.32]\n",
      " [0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted averages:\", p_wise.averages(), \"Predicted correlations:\", p_wise.correlations(),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0] 0.406\n",
      "[0 0 1] 0.074\n",
      "[0 1 0] 0.074\n",
      "[0 1 1] 0.246\n",
      "[1 0 0] 0.074\n",
      "[1 0 1] 0.046\n",
      "[1 1 0] 0.006\n",
      "[1 1 1] 0.074\n"
     ]
    }
   ],
   "source": [
    "for state in p_wise.states:\n",
    "    print(state,np.round(p_wise.p(state),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] 0.48\n",
      "[0, 1, 1] 0.32000000000000006\n",
      "[1, 0, 1] 0.12\n",
      "[1, 1, 0] 0.08000000000000002\n"
     ]
    }
   ],
   "source": [
    "print([0,0,0], (1-a)*(1-b))\n",
    "print([0,1,1], (1-a)*b)\n",
    "print([1,0,1], a*(1-b))\n",
    "print([1,1,0], a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the events `[0,0,1]` and `[1,1,1]` are assigned non-zero probabilities, when they should in fact be zero. In general, we can see the predictions are far off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('.venv')",
   "language": "python",
   "name": "python39264bitvenv6ba9df577454428a8bb273d87ec6817e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
